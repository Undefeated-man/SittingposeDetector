{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "76e6899a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.92 0\n",
      "0.8 1\n",
      "0.8 2\n",
      "0.88 3\n",
      "0.88 4\n",
      "0.84 5\n",
      "0.8 6\n",
      "0.72 7\n",
      "0.8 8\n",
      "0.8 9\n",
      "0.76 10\n",
      "0.88 11\n",
      "0.84 12\n",
      "0.88 13\n",
      "0.92 14\n",
      "0.88 15\n",
      "0.92 16\n",
      "0.72 17\n",
      "0.96 18\n",
      "0.84 19\n",
      "[(0.92, 0), (0.8, 1), (0.8, 2), (0.88, 3), (0.88, 4), (0.84, 5), (0.8, 6), (0.72, 7), (0.8, 8), (0.8, 9), (0.76, 10), (0.88, 11), (0.84, 12), (0.88, 13), (0.92, 14), (0.88, 15), (0.92, 16), (0.72, 17), (0.96, 18), (0.84, 19)]\n",
      "0.8420000000000002\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import tensorflow as tf\n",
    "from PIL import Image,ImageFont,ImageDraw\n",
    "import os\n",
    "import skimage.io\n",
    "import skimage.color\n",
    "import skimage.transform\n",
    "import random\n",
    "from sklearn import svm\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "final_score = []\n",
    "total_score = 0\n",
    "for seed in range(20):    \n",
    "    random.seed(seed)\n",
    "    DATASET_DIR = './data/'\n",
    "    classes = os.listdir(DATASET_DIR)\n",
    "    data = []\n",
    "    for cls in classes:\n",
    "        files = os.listdir(DATASET_DIR + cls)\n",
    "        for f in files:\n",
    "            img = skimage.io.imread(DATASET_DIR + cls + \"/\" + f)\n",
    "            #img = skimage.color.rgb2gray(img)\n",
    "            if cls == \"good_sit\": \n",
    "                y = 0\n",
    "            else:\n",
    "                y = 1\n",
    "            data.append({\n",
    "                'x': img,\n",
    "                'y': y\n",
    "            })\n",
    "    random.shuffle(data)\n",
    "    X = [d['x'] for d in data]\n",
    "    Y = [[d['y']] for d in data]\n",
    "\n",
    "    # 检测模型\n",
    "    file_model = \"posenet_mobilenet_v1_100_257x257_multi_kpt_stripped.tflite\"\n",
    "\n",
    "    interpreter = tf.lite.Interpreter(model_path=file_model)\n",
    "    interpreter.allocate_tensors()\n",
    "\n",
    "    # 获取输入、输出的数据的信息\n",
    "    input_details = interpreter.get_input_details()\n",
    "    #print('input_details\\n',input_details)\n",
    "    output_details = interpreter.get_output_details()\n",
    "    #print('output_details',output_details)\n",
    "\n",
    "\n",
    "    # 获取PosNet 要求输入图像的高和宽\n",
    "    height = input_details[0]['shape'][1]\n",
    "    width = input_details[0]['shape'][2]\n",
    "\n",
    "    key_data = [[]]\n",
    "    for img in X:\n",
    "        # 获取图像帧的尺寸\n",
    "        imH,imW,_ = np.shape(img)\n",
    "\n",
    "        # 适当缩放\n",
    "        img = cv2.resize(img,(int(imW*0.5),int(imH*0.5)))\n",
    "\n",
    "        # 获取图像帧的尺寸\n",
    "        imH,imW,_ = np.shape(img)\n",
    "\n",
    "        # BGR 转RGB\n",
    "        img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "        # 尺寸缩放适应PosNet 网络输入要求\n",
    "        img_resized = cv2.resize(img_rgb, (width, height))\n",
    "\n",
    "        # 维度扩张适应网络输入要求\n",
    "        input_data = np.expand_dims(img_resized, axis=0)\n",
    "\n",
    "        # 尺度缩放 变为 -1~+1\n",
    "        input_data = (np.float32(input_data) - 128.0)/128.0\n",
    "\n",
    "        # 数据输入网络\n",
    "        interpreter.set_tensor(input_details[0]['index'],input_data)\n",
    "\n",
    "        # 进行关键点检测\n",
    "        interpreter.invoke()\n",
    "\n",
    "        # 获取hotmat\n",
    "        hotmaps = interpreter.get_tensor(output_details[0]['index'])[0] # Bounding box coordinates of detected objects\n",
    "\n",
    "        # 获取偏移量\n",
    "        offsets = interpreter.get_tensor(output_details[1]['index'])[0] # Class index of detected objects\n",
    "\n",
    "        # 获取hotmat的 宽 高 以及关键的数目\n",
    "        h_output,w_output, n_KeyPoints= np.shape(hotmaps)\n",
    "\n",
    "        # 存储关键点的具体位置\n",
    "        keypoints =[]\n",
    "\n",
    "        # 关键点的置信度\n",
    "        score_ = []\n",
    "        for i in range(11):\n",
    "            # 遍历每一张hotmap\n",
    "            hotmap = hotmaps[:,:,i]\n",
    "\n",
    "            # 获取最大值 和最大值的位置\n",
    "            max_index = np.where(hotmap==np.max(hotmap))\n",
    "            max_val   = np.max(hotmap)\n",
    "\n",
    "            # 获取y，x偏移量 前n_KeyPoints张图是y的偏移 后n_KeyPoints张图是x的偏移\n",
    "            offset_y = offsets[max_index[0],max_index[1],i]\n",
    "            offset_x = offsets[max_index[0],max_index[1],i+n_KeyPoints]\n",
    "\n",
    "            # 计算在posnet输入图像中具体的坐标\n",
    "            pos_y = max_index[0]/(h_output-1)*height + offset_y\n",
    "            pos_x = max_index[1]/(w_output-1)*width + offset_x\n",
    "\n",
    "            # 计算在源图像中的坐标\n",
    "            pos_y = pos_y/(height-1)*imH\n",
    "            pos_x = pos_x/(width-1)*imW\n",
    "\n",
    "            #算置信度\n",
    "            score = 1.0/(1.0+np.exp(-max_val))\n",
    "\n",
    "            # 取整获得keypoints的位置\n",
    "            if score>0.2:\n",
    "                key_data[-1].append(int(round(pos_x[0])))\n",
    "                key_data[-1].append(int(round(pos_y[0])))\n",
    "            else:\n",
    "                key_data[-1].append(-1)\n",
    "                key_data[-1].append(-1)\n",
    "            #score_.append(score)\n",
    "\n",
    "        #print(keypoints[:11], score_)   \n",
    "        #key_data.append(keypoints[:22])\n",
    "        key_data.append([])\n",
    "    key_data = key_data[:-1]\n",
    "\n",
    "    X_train = np.array(key_data[:-25])\n",
    "    Y_train = np.array(Y[:-25])\n",
    "    X_test  = np.array(key_data[-25:])\n",
    "    Y_test  = np.array(Y[-25:])\n",
    "\n",
    "    assert len(X_train) == len(Y_train)\n",
    "    assert len(X_test)  == len(Y_test)\n",
    "\n",
    "    svc = svm.SVC(kernel=\"rbf\")\n",
    "    svc.fit(X_train, Y_train)\n",
    "    a = svc.score(X_test, Y_test)\n",
    "    print(a,seed)\n",
    "    final_score.append((a, seed))\n",
    "    total_score += a\n",
    "print(final_score)\n",
    "print(total_score/20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b3f06cb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.92 0\n",
      "0.84 1\n",
      "0.88 2\n",
      "0.96 3\n",
      "0.8 4\n",
      "0.76 5\n",
      "0.84 6\n",
      "0.76 7\n",
      "0.88 8\n",
      "0.8 9\n",
      "0.84 10\n",
      "0.88 11\n",
      "0.84 12\n",
      "0.8 13\n",
      "0.84 14\n",
      "0.88 15\n",
      "0.84 16\n",
      "0.68 17\n",
      "0.92 18\n",
      "0.8 19\n",
      "[(0.92, 0), (0.84, 1), (0.88, 2), (0.96, 3), (0.8, 4), (0.76, 5), (0.84, 6), (0.76, 7), (0.88, 8), (0.8, 9), (0.84, 10), (0.88, 11), (0.84, 12), (0.8, 13), (0.84, 14), (0.88, 15), (0.84, 16), (0.68, 17), (0.92, 18), (0.8, 19)]\n",
      "0.8380000000000001\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import tensorflow as tf\n",
    "from PIL import Image,ImageFont,ImageDraw\n",
    "import os\n",
    "import skimage.io\n",
    "import skimage.color\n",
    "import skimage.transform\n",
    "import random\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "final_score = []\n",
    "total_score = 0\n",
    "for seed in range(20):    \n",
    "    random.seed(seed)\n",
    "    DATASET_DIR = './data/'\n",
    "    classes = os.listdir(DATASET_DIR)\n",
    "    data = []\n",
    "    for cls in classes:\n",
    "        files = os.listdir(DATASET_DIR + cls)\n",
    "        for f in files:\n",
    "            img = skimage.io.imread(DATASET_DIR + cls + \"/\" + f)\n",
    "            #img = skimage.color.rgb2gray(img)\n",
    "            if cls == \"good_sit\": \n",
    "                y = 0\n",
    "            else:\n",
    "                y = 1\n",
    "            data.append({\n",
    "                'x': img,\n",
    "                'y': y\n",
    "            })\n",
    "    random.shuffle(data)\n",
    "    X = [d['x'] for d in data]\n",
    "    Y = [[d['y']] for d in data]\n",
    "\n",
    "    # 检测模型\n",
    "    file_model = \"posenet_mobilenet_v1_100_257x257_multi_kpt_stripped.tflite\"\n",
    "\n",
    "    interpreter = tf.lite.Interpreter(model_path=file_model)\n",
    "    interpreter.allocate_tensors()\n",
    "\n",
    "    # 获取输入、输出的数据的信息\n",
    "    input_details = interpreter.get_input_details()\n",
    "    #print('input_details\\n',input_details)\n",
    "    output_details = interpreter.get_output_details()\n",
    "    #print('output_details',output_details)\n",
    "\n",
    "\n",
    "    # 获取PosNet 要求输入图像的高和宽\n",
    "    height = input_details[0]['shape'][1]\n",
    "    width = input_details[0]['shape'][2]\n",
    "\n",
    "    key_data = [[]]\n",
    "    for img in X:\n",
    "        # 获取图像帧的尺寸\n",
    "        imH,imW,_ = np.shape(img)\n",
    "\n",
    "        # 适当缩放\n",
    "        img = cv2.resize(img,(int(imW*0.5),int(imH*0.5)))\n",
    "\n",
    "        # 获取图像帧的尺寸\n",
    "        imH,imW,_ = np.shape(img)\n",
    "\n",
    "        # BGR 转RGB\n",
    "        img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "        # 尺寸缩放适应PosNet 网络输入要求\n",
    "        img_resized = cv2.resize(img_rgb, (width, height))\n",
    "\n",
    "        # 维度扩张适应网络输入要求\n",
    "        input_data = np.expand_dims(img_resized, axis=0)\n",
    "\n",
    "        # 尺度缩放 变为 -1~+1\n",
    "        input_data = (np.float32(input_data) - 128.0)/128.0\n",
    "\n",
    "        # 数据输入网络\n",
    "        interpreter.set_tensor(input_details[0]['index'],input_data)\n",
    "\n",
    "        # 进行关键点检测\n",
    "        interpreter.invoke()\n",
    "\n",
    "        # 获取hotmat\n",
    "        hotmaps = interpreter.get_tensor(output_details[0]['index'])[0] # Bounding box coordinates of detected objects\n",
    "\n",
    "        # 获取偏移量\n",
    "        offsets = interpreter.get_tensor(output_details[1]['index'])[0] # Class index of detected objects\n",
    "\n",
    "        # 获取hotmat的 宽 高 以及关键的数目\n",
    "        h_output,w_output, n_KeyPoints= np.shape(hotmaps)\n",
    "\n",
    "        # 存储关键点的具体位置\n",
    "        keypoints =[]\n",
    "\n",
    "        # 关键点的置信度\n",
    "        score_ = []\n",
    "        for i in range(11):\n",
    "            # 遍历每一张hotmap\n",
    "            hotmap = hotmaps[:,:,i]\n",
    "\n",
    "            # 获取最大值 和最大值的位置\n",
    "            max_index = np.where(hotmap==np.max(hotmap))\n",
    "            max_val   = np.max(hotmap)\n",
    "\n",
    "            # 获取y，x偏移量 前n_KeyPoints张图是y的偏移 后n_KeyPoints张图是x的偏移\n",
    "            offset_y = offsets[max_index[0],max_index[1],i]\n",
    "            offset_x = offsets[max_index[0],max_index[1],i+n_KeyPoints]\n",
    "\n",
    "            # 计算在posnet输入图像中具体的坐标\n",
    "            pos_y = max_index[0]/(h_output-1)*height + offset_y\n",
    "            pos_x = max_index[1]/(w_output-1)*width + offset_x\n",
    "\n",
    "            # 计算在源图像中的坐标\n",
    "            pos_y = pos_y/(height-1)*imH\n",
    "            pos_x = pos_x/(width-1)*imW\n",
    "\n",
    "            #算置信度\n",
    "            score = 1.0/(1.0+np.exp(-max_val))\n",
    "\n",
    "            # 取整获得keypoints的位置\n",
    "            if score>0.2:\n",
    "                key_data[-1].append(int(round(pos_x[0])))\n",
    "                key_data[-1].append(int(round(pos_y[0])))\n",
    "            else:\n",
    "                key_data[-1].append(-1)\n",
    "                key_data[-1].append(-1)\n",
    "            #score_.append(score)\n",
    "\n",
    "        #print(keypoints[:11], score_)   \n",
    "        #key_data.append(keypoints[:22])\n",
    "        key_data.append([])\n",
    "    key_data = key_data[:-1]\n",
    "\n",
    "    X_train = np.array(key_data[:-25])\n",
    "    Y_train = np.array(Y[:-25])\n",
    "    X_test  = np.array(key_data[-25:])\n",
    "    Y_test  = np.array(Y[-25:])\n",
    "\n",
    "    assert len(X_train) == len(Y_train)\n",
    "    assert len(X_test)  == len(Y_test)\n",
    "\n",
    "    model = LogisticRegression().fit(X_train, Y_train)\n",
    "    a = model.score(X_test, Y_test)\n",
    "    print(a,seed)\n",
    "    final_score.append((a, seed))\n",
    "    total_score += a\n",
    "print(final_score)\n",
    "print(total_score/20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1ee3a026",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.92 0\n",
      "0.92 1\n",
      "0.76 2\n",
      "0.92 3\n",
      "0.76 4\n",
      "0.8 5\n",
      "0.88 6\n",
      "0.88 7\n",
      "0.84 8\n",
      "0.76 9\n",
      "0.92 10\n",
      "0.84 11\n",
      "0.92 12\n",
      "0.92 13\n",
      "0.88 14\n",
      "0.92 15\n",
      "0.88 16\n",
      "0.92 17\n",
      "0.84 18\n",
      "0.88 19\n",
      "[(0.92, 0), (0.92, 1), (0.76, 2), (0.92, 3), (0.76, 4), (0.8, 5), (0.88, 6), (0.88, 7), (0.84, 8), (0.76, 9), (0.92, 10), (0.84, 11), (0.92, 12), (0.92, 13), (0.88, 14), (0.92, 15), (0.88, 16), (0.92, 17), (0.84, 18), (0.88, 19)]\n",
      "0.868\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import tensorflow as tf\n",
    "from PIL import Image,ImageFont,ImageDraw\n",
    "import os\n",
    "import skimage.io\n",
    "import skimage.color\n",
    "import skimage.transform\n",
    "import random\n",
    "from sklearn import tree\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "final_score = []\n",
    "total_score = 0\n",
    "for seed in range(20):    \n",
    "    random.seed(seed)\n",
    "    DATASET_DIR = './data/'\n",
    "    classes = os.listdir(DATASET_DIR)\n",
    "    data = []\n",
    "    for cls in classes:\n",
    "        files = os.listdir(DATASET_DIR + cls)\n",
    "        for f in files:\n",
    "            img = skimage.io.imread(DATASET_DIR + cls + \"/\" + f)\n",
    "            #img = skimage.color.rgb2gray(img)\n",
    "            if cls == \"good_sit\": \n",
    "                y = 0\n",
    "            else:\n",
    "                y = 1\n",
    "            data.append({\n",
    "                'x': img,\n",
    "                'y': y\n",
    "            })\n",
    "    random.shuffle(data)\n",
    "    X = [d['x'] for d in data]\n",
    "    Y = [[d['y']] for d in data]\n",
    "\n",
    "    # 检测模型\n",
    "    file_model = \"posenet_mobilenet_v1_100_257x257_multi_kpt_stripped.tflite\"\n",
    "\n",
    "    interpreter = tf.lite.Interpreter(model_path=file_model)\n",
    "    interpreter.allocate_tensors()\n",
    "\n",
    "    # 获取输入、输出的数据的信息\n",
    "    input_details = interpreter.get_input_details()\n",
    "    #print('input_details\\n',input_details)\n",
    "    output_details = interpreter.get_output_details()\n",
    "    #print('output_details',output_details)\n",
    "\n",
    "\n",
    "    # 获取PosNet 要求输入图像的高和宽\n",
    "    height = input_details[0]['shape'][1]\n",
    "    width = input_details[0]['shape'][2]\n",
    "\n",
    "    key_data = [[]]\n",
    "    for img in X:\n",
    "        # 获取图像帧的尺寸\n",
    "        imH,imW,_ = np.shape(img)\n",
    "\n",
    "        # 适当缩放\n",
    "        img = cv2.resize(img,(int(imW*0.5),int(imH*0.5)))\n",
    "\n",
    "        # 获取图像帧的尺寸\n",
    "        imH,imW,_ = np.shape(img)\n",
    "\n",
    "        # BGR 转RGB\n",
    "        img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "        # 尺寸缩放适应PosNet 网络输入要求\n",
    "        img_resized = cv2.resize(img_rgb, (width, height))\n",
    "\n",
    "        # 维度扩张适应网络输入要求\n",
    "        input_data = np.expand_dims(img_resized, axis=0)\n",
    "\n",
    "        # 尺度缩放 变为 -1~+1\n",
    "        input_data = (np.float32(input_data) - 128.0)/128.0\n",
    "\n",
    "        # 数据输入网络\n",
    "        interpreter.set_tensor(input_details[0]['index'],input_data)\n",
    "\n",
    "        # 进行关键点检测\n",
    "        interpreter.invoke()\n",
    "\n",
    "        # 获取hotmat\n",
    "        hotmaps = interpreter.get_tensor(output_details[0]['index'])[0] # Bounding box coordinates of detected objects\n",
    "\n",
    "        # 获取偏移量\n",
    "        offsets = interpreter.get_tensor(output_details[1]['index'])[0] # Class index of detected objects\n",
    "\n",
    "        # 获取hotmat的 宽 高 以及关键的数目\n",
    "        h_output,w_output, n_KeyPoints= np.shape(hotmaps)\n",
    "\n",
    "        # 存储关键点的具体位置\n",
    "        keypoints =[]\n",
    "\n",
    "        # 关键点的置信度\n",
    "        score_ = []\n",
    "        for i in range(11):\n",
    "            # 遍历每一张hotmap\n",
    "            hotmap = hotmaps[:,:,i]\n",
    "\n",
    "            # 获取最大值 和最大值的位置\n",
    "            max_index = np.where(hotmap==np.max(hotmap))\n",
    "            max_val   = np.max(hotmap)\n",
    "\n",
    "            # 获取y，x偏移量 前n_KeyPoints张图是y的偏移 后n_KeyPoints张图是x的偏移\n",
    "            offset_y = offsets[max_index[0],max_index[1],i]\n",
    "            offset_x = offsets[max_index[0],max_index[1],i+n_KeyPoints]\n",
    "\n",
    "            # 计算在posnet输入图像中具体的坐标\n",
    "            pos_y = max_index[0]/(h_output-1)*height + offset_y\n",
    "            pos_x = max_index[1]/(w_output-1)*width + offset_x\n",
    "\n",
    "            # 计算在源图像中的坐标\n",
    "            pos_y = pos_y/(height-1)*imH\n",
    "            pos_x = pos_x/(width-1)*imW\n",
    "\n",
    "            #算置信度\n",
    "            score = 1.0/(1.0+np.exp(-max_val))\n",
    "\n",
    "            # 取整获得keypoints的位置\n",
    "            if score>0.2:\n",
    "                key_data[-1].append(int(round(pos_x[0])))\n",
    "                key_data[-1].append(int(round(pos_y[0])))\n",
    "            else:\n",
    "                key_data[-1].append(-1)\n",
    "                key_data[-1].append(-1)\n",
    "            #score_.append(score)\n",
    "\n",
    "        #print(keypoints[:11], score_)   \n",
    "        #key_data.append(keypoints[:22])\n",
    "        key_data.append([])\n",
    "    key_data = key_data[:-1]\n",
    "\n",
    "    X_train = np.array(key_data[:-25])\n",
    "    Y_train = np.array(Y[:-25])\n",
    "    X_test  = np.array(key_data[-25:])\n",
    "    Y_test  = np.array(Y[-25:])\n",
    "\n",
    "    assert len(X_train) == len(Y_train)\n",
    "    assert len(X_test)  == len(Y_test)\n",
    "\n",
    "    model = tree.DecisionTreeClassifier().fit(X_train, Y_train)\n",
    "    a = model.score(X_test, Y_test)\n",
    "    print(a,seed)\n",
    "    final_score.append((a, seed))\n",
    "    total_score += a\n",
    "print(final_score)\n",
    "print(total_score/20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "983c6cc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.96 0\n",
      "0.96 1\n",
      "0.88 2\n",
      "0.96 3\n",
      "0.88 4\n",
      "0.84 5\n",
      "0.96 6\n",
      "0.88 7\n",
      "0.92 8\n",
      "0.92 9\n",
      "0.92 10\n",
      "0.88 11\n",
      "0.88 12\n",
      "0.96 13\n",
      "0.96 14\n",
      "1.0 15\n",
      "1.0 16\n",
      "0.92 17\n",
      "1.0 18\n",
      "1.0 19\n",
      "[(0.96, 0), (0.96, 1), (0.88, 2), (0.96, 3), (0.88, 4), (0.84, 5), (0.96, 6), (0.88, 7), (0.92, 8), (0.92, 9), (0.92, 10), (0.88, 11), (0.88, 12), (0.96, 13), (0.96, 14), (1.0, 15), (1.0, 16), (0.92, 17), (1.0, 18), (1.0, 19)]\n",
      "0.9340000000000002\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import tensorflow as tf\n",
    "from PIL import Image,ImageFont,ImageDraw\n",
    "import os\n",
    "import skimage.io\n",
    "import skimage.color\n",
    "import skimage.transform\n",
    "import random\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "final_score = []\n",
    "total_score = 0\n",
    "for seed in range(20):    \n",
    "    random.seed(seed)\n",
    "    DATASET_DIR = './data/'\n",
    "    classes = os.listdir(DATASET_DIR)\n",
    "    data = []\n",
    "    for cls in classes:\n",
    "        files = os.listdir(DATASET_DIR + cls)\n",
    "        for f in files:\n",
    "            img = skimage.io.imread(DATASET_DIR + cls + \"/\" + f)\n",
    "            #img = skimage.color.rgb2gray(img)\n",
    "            if cls == \"good_sit\": \n",
    "                y = 0\n",
    "            else:\n",
    "                y = 1\n",
    "            data.append({\n",
    "                'x': img,\n",
    "                'y': y\n",
    "            })\n",
    "    random.shuffle(data)\n",
    "    X = [d['x'] for d in data]\n",
    "    Y = [[d['y']] for d in data]\n",
    "\n",
    "    # 检测模型\n",
    "    file_model = \"posenet_mobilenet_v1_100_257x257_multi_kpt_stripped.tflite\"\n",
    "\n",
    "    interpreter = tf.lite.Interpreter(model_path=file_model)\n",
    "    interpreter.allocate_tensors()\n",
    "\n",
    "    # 获取输入、输出的数据的信息\n",
    "    input_details = interpreter.get_input_details()\n",
    "    #print('input_details\\n',input_details)\n",
    "    output_details = interpreter.get_output_details()\n",
    "    #print('output_details',output_details)\n",
    "\n",
    "\n",
    "    # 获取PosNet 要求输入图像的高和宽\n",
    "    height = input_details[0]['shape'][1]\n",
    "    width = input_details[0]['shape'][2]\n",
    "\n",
    "    key_data = [[]]\n",
    "    for img in X:\n",
    "        # 获取图像帧的尺寸\n",
    "        imH,imW,_ = np.shape(img)\n",
    "\n",
    "        # 适当缩放\n",
    "        img = cv2.resize(img,(int(imW*0.5),int(imH*0.5)))\n",
    "\n",
    "        # 获取图像帧的尺寸\n",
    "        imH,imW,_ = np.shape(img)\n",
    "\n",
    "        # BGR 转RGB\n",
    "        img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "        # 尺寸缩放适应PosNet 网络输入要求\n",
    "        img_resized = cv2.resize(img_rgb, (width, height))\n",
    "\n",
    "        # 维度扩张适应网络输入要求\n",
    "        input_data = np.expand_dims(img_resized, axis=0)\n",
    "\n",
    "        # 尺度缩放 变为 -1~+1\n",
    "        input_data = (np.float32(input_data) - 128.0)/128.0\n",
    "\n",
    "        # 数据输入网络\n",
    "        interpreter.set_tensor(input_details[0]['index'],input_data)\n",
    "\n",
    "        # 进行关键点检测\n",
    "        interpreter.invoke()\n",
    "\n",
    "        # 获取hotmat\n",
    "        hotmaps = interpreter.get_tensor(output_details[0]['index'])[0] # Bounding box coordinates of detected objects\n",
    "\n",
    "        # 获取偏移量\n",
    "        offsets = interpreter.get_tensor(output_details[1]['index'])[0] # Class index of detected objects\n",
    "\n",
    "        # 获取hotmat的 宽 高 以及关键的数目\n",
    "        h_output,w_output, n_KeyPoints= np.shape(hotmaps)\n",
    "\n",
    "        # 存储关键点的具体位置\n",
    "        keypoints =[]\n",
    "\n",
    "        # 关键点的置信度\n",
    "        score_ = []\n",
    "        for i in range(11):\n",
    "            # 遍历每一张hotmap\n",
    "            hotmap = hotmaps[:,:,i]\n",
    "\n",
    "            # 获取最大值 和最大值的位置\n",
    "            max_index = np.where(hotmap==np.max(hotmap))\n",
    "            max_val   = np.max(hotmap)\n",
    "\n",
    "            # 获取y，x偏移量 前n_KeyPoints张图是y的偏移 后n_KeyPoints张图是x的偏移\n",
    "            offset_y = offsets[max_index[0],max_index[1],i]\n",
    "            offset_x = offsets[max_index[0],max_index[1],i+n_KeyPoints]\n",
    "\n",
    "            # 计算在posnet输入图像中具体的坐标\n",
    "            pos_y = max_index[0]/(h_output-1)*height + offset_y\n",
    "            pos_x = max_index[1]/(w_output-1)*width + offset_x\n",
    "\n",
    "            # 计算在源图像中的坐标\n",
    "            pos_y = pos_y/(height-1)*imH\n",
    "            pos_x = pos_x/(width-1)*imW\n",
    "\n",
    "            #算置信度\n",
    "            score = 1.0/(1.0+np.exp(-max_val))\n",
    "\n",
    "            # 取整获得keypoints的位置\n",
    "            if score>0.2:\n",
    "                key_data[-1].append(int(round(pos_x[0])))\n",
    "                key_data[-1].append(int(round(pos_y[0])))\n",
    "            else:\n",
    "                key_data[-1].append(-1)\n",
    "                key_data[-1].append(-1)\n",
    "            #score_.append(score)\n",
    "\n",
    "        #print(keypoints[:11], score_)   \n",
    "        #key_data.append(keypoints[:22])\n",
    "        key_data.append([])\n",
    "    key_data = key_data[:-1]\n",
    "\n",
    "    X_train = np.array(key_data[:-25])\n",
    "    Y_train = np.array(Y[:-25])\n",
    "    X_test  = np.array(key_data[-25:])\n",
    "    Y_test  = np.array(Y[-25:])\n",
    "\n",
    "    assert len(X_train) == len(Y_train)\n",
    "    assert len(X_test)  == len(Y_test)\n",
    "\n",
    "    model = RandomForestClassifier().fit(X_train, Y_train)\n",
    "    a = model.score(X_test, Y_test)\n",
    "    total_score += a\n",
    "    print(a,seed)\n",
    "    final_score.append((a,seed))\n",
    "print(final_score)\n",
    "print(total_score/20)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
